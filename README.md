# Project description: 
In this project, the text corpus is the writing of German philosopher Nietzsche. An LSTM model is trained such that given N characters of the writers text, the next character will be generated by the model.

Sequences of given length are extracted from the writing, one-hot encoded and described as 3D Numpy array and then the target character of each array is also determined.

Network model: An LSTM layer with 128 cells is used and then the output is connected to a Dense layer with softmax activation.


Sampling of the next character is done based on a multinomial distribution computed with given entropy or temperature. 

For 60 epochs, the model is fitted to the training data with batch sizes of 128. A text of length 400 is then generated for different values of temperature.
